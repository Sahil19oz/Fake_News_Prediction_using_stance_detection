{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING STANCE DETECTION TO FIND RELATIVE ARTICLES OR NEWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING ARTICLE LIBRARY TO EXTRACT NEWSPAPER ARTICLES FROM GOOGLE SEARCH RESULTS\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the headline you're willing to extract:KASHMIR WILL CELEBRATE EID HAPPILY AND FREELY THIS YEAR\n"
     ]
    }
   ],
   "source": [
    "#PLACEHOLDER FOR THE ARTICLE LINK,HEADLINE OR WHOLE SUMMARY TO INPUT FROM USER \n",
    "global headline_input\n",
    "headline_input=input(\"Enter the headline you're willing to extract:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "url=[]\n",
    "article=[]\n",
    "headline=[]\n",
    "urls=[]\n",
    "domain=[]\n",
    "try: \n",
    "    from googlesearch import search \n",
    "except ImportError:  \n",
    "    print(\"No module named 'google' found\") \n",
    "\n",
    "# to search \n",
    "query =headline_input \n",
    "for j in search(query, tld=\"com\", num=10, stop=10, pause=2): \n",
    "    url.append(str(j))\n",
    "    \n",
    "for i in range(0,len(url)):\n",
    "    article.append(Article(url[i], language=\"en\"))\n",
    "    article[i].download()\n",
    "    try:\n",
    "        article[i].parse()\n",
    "        headline.append(article[i].title)\n",
    "        title.append(article[i].url)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "for k in urls:\n",
    "    print(result = '{uri.scheme}://{uri.netloc}/'.format(uri=urlparse(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE EXTRACTED TOP 10 RESULTS FROM THE GOOGLE SEARCH AND NOW WE WILL COMPARE OUR INPUT TEXT WITH THESE HEADLINES USING DOC2VEC\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT THE HEADLINE INTO PROPER FORM REMOVING STOPWORDS,ETC\n",
    "data=headline\n",
    "tagged_data=[TaggedDocument(words=word_tokenize(_d.lower()),tags=[str(i)]) for i,_d in enumerate(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\home\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\models\\doc2vec.py:575: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
      "c:\\users\\home\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "c:\\users\\home\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs=100\n",
    "vec_size=20\n",
    "alpha=0.025\n",
    "model=Doc2Vec(size=vec_size,alpha=alpha,min_alpha=0.00025,min_count=1,dm=1)\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    #print(\"iteration{0}\".format(epoch))\n",
    "    model.train(tagged_data,total_examples=model.corpus_count,epochs=model.iter)\n",
    "    model.alpha-=0.0002\n",
    "    model.min_alpha=model.alpha\n",
    "model.save(\"d2v.model\")\n",
    "print(\"model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2', 0.7377285957336426), ('5', 0.733738899230957), ('0', 0.6799396276473999), ('9', 0.6282100081443787), ('6', 0.6011895537376404), ('4', 0.5890125632286072), ('7', 0.5734545588493347), ('8', 0.5013601183891296), ('3', 0.28389251232147217)]\n",
      "['kashmir', 'will', 'celebrate', 'eid', 'happily', 'and', 'freely', 'this', 'year']\n",
      "\n",
      "sim=0.7377\n",
      "Eid al-Fitr 2019: Everything you need to know\n",
      "\n",
      "sim=0.7337\n",
      "The feast begins: how Muslims in conflict-torn Kashmir celebrate Eid, in pictures\n",
      "\n",
      "sim=0.6799\n",
      "India-held Kashmir celebrates Eid with Pakistan\n",
      "\n",
      "sim=0.6282\n",
      "Eid al Fitr 2019: When does Ramadan end? How do you celebrate Eid al Fitr 2019?\n",
      "\n",
      "sim=0.6012\n",
      "When is Eid 2019 and how do Muslims celebrate the end of Ramadan?\n",
      "\n",
      "sim=0.5890\n",
      "eid al fitr: Latest News, Videos and eid al fitr Photos\n",
      "\n",
      "sim=0.5735\n",
      "Shawwal Moon Sighted in Saudi Arabia, Eid-ul-Fitr to be Celebrated Today\n",
      "\n",
      "sim=0.5014\n",
      "Eid-ul-Fitr 2019 Moon Sighting: India to celebrate Eid on June 5; UAE, Saudi Arabia celebrate today\n",
      "\n",
      "sim=0.2839\n",
      "Eid al-Adha 2019: Wishes, greetings, images to share on SMS, WhatsApp, Facebook and Instagram\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model=Doc2Vec.load(\"d2v.model\")\n",
    "test_data=word_tokenize(headline_input.lower())\n",
    "v1=model.infer_vector(test_data)\n",
    "#print(\"V1_infer\",v1)\n",
    "\n",
    "similar_doc=model.docvecs.most_similar(\"1\")\n",
    "print(similar_doc)\n",
    "print(test_data)\n",
    "for i in range(len(similar_doc)):\n",
    "    print()\n",
    "    print(\"sim=%.4f\" %similar_doc[i][1])\n",
    "    print(headline[int(similar_doc[i][0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying a word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gensim.models import Word2Vec\n",
    "from newspaper import Article\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING PREDEFINED LIBRARY TEXTBLOB FOR FINDING THE SENTIMENT OF THE SENTENCE OR ARTICLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEXTBLOB IS A SIMPLE LIBRARY\n",
    "from textblob import TextBlob\n",
    "tag=TextBlob(headline[4])\n",
    "tag.words\n",
    "tag.sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
